{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import PIL.Image\n",
    "import itertools\n",
    "from IPython.core.display import Image, display\n",
    "import scipy.ndimage\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import tqdm\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from matplotlib.pyplot import figure\n",
    "%matplotlib inline\n",
    "\n",
    "# Parameters\n",
    "random_seed = 42\n",
    "random_std_dev = 1e-4\n",
    "norm_epsilon = 1e-4\n",
    "epochs = 5000\n",
    "eta = 4.2e-6\n",
    "acc_eps = 5e-3\n",
    "lamda = 1e-4\n",
    "\n",
    "# Functions\n",
    "def sigmoid(x):\n",
    "    return 1. / (1 + np.exp(-x))\n",
    "\n",
    "def model(x, w):\n",
    "    return sigmoid(np.dot(w.T, x))\n",
    "\n",
    "def logloss(x, y, w):\n",
    "    return sum(np.log(1. + np.exp(-y[i] * np.dot(w.T, x[i]))) for i in range(len(y))) / len(y)\n",
    "\n",
    "def accuracy(pred, true):\n",
    "    return sum(float(t - p <= acc_eps) if t == 1 else float(p <= acc_eps) for p, t in zip(pred, true)) / len(true)\n",
    "\n",
    "def gradient_loss(x, y, w, j):\n",
    "    return - y[j] * x[j] / (1 + np.exp(y[j] * np.dot(w.T, x[j]))) + lamda * w\n",
    "\n",
    "def evaluation(pred, x, y, w):\n",
    "    return [logloss(x, y, w), accuracy(pred, y)]\n",
    "\n",
    "def data_normalization(data):\n",
    "    mean = np.mean(data)\n",
    "    std = np.std(data)\n",
    "    return (data - mean) / (std + norm_epsilon)\n",
    "    \n",
    "with open('./hw_1_train.pickle', 'rb') as f:\n",
    "    train = pickle.load(f)\n",
    "\n",
    "with open('./hw_1_test_no_lables.pickle', 'rb') as f:\n",
    "    test = pickle.load(f)\n",
    "\n",
    "data = train['data']\n",
    "labels = train['labels']\n",
    "\n",
    "# Normalization of the input data\n",
    "data = data_normalization(data)\n",
    "\n",
    "# Tag Conversion\n",
    "labels[labels==5] = -1\n",
    "labels[labels==6] = 1\n",
    "\n",
    "# Splitting data on the training and the test samples\n",
    "x_train, x_test, y_train, y_test = train_test_split(data, labels, random_state=10)\n",
    "\n",
    "# Arrays' dimensions\n",
    "width = x_train.shape[1]\n",
    "tr_length = x_train.shape[0]\n",
    "te_length = x_test.shape[0]\n",
    "\n",
    "# Random weight initialization\n",
    "np.random.seed(random_seed)\n",
    "w = np.random.normal(scale=random_std_dev, size=width)\n",
    "\n",
    "# Arrays for evaluation\n",
    "tr_eval, te_eval = [], []\n",
    "\n",
    "# Training model\n",
    "for iter in tqdm.tqdm_notebook(range(epochs)):\n",
    "    for i in range(tr_length):\n",
    "        j = np.random.randint(0, tr_length)\n",
    "        gl = gradient_loss(x_train, y_train, w, j)\n",
    "        w = w - eta * gl\n",
    "\n",
    "    tr_pred = [model(x_train[i], w) for i in range(tr_length)]\n",
    "    te_pred = [model(x_test[i], w) for i in range(te_length)]\n",
    "    \n",
    "    tr_eval.append(evaluation(tr_pred, x_train, y_train, w))\n",
    "    te_eval.append(evaluation(te_pred, x_test, y_test, w))\n",
    "\n",
    "# Plotting loss and accuracy \n",
    "figure(num=None, figsize=(14, 6), dpi=80, facecolor='w', edgecolor='k')\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot([l[0] for l in tr_eval], label='train')\n",
    "plt.plot([l[0] for l in te_eval], label='test')\n",
    "plt.xlabel('Loss')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot([a[1] for a in tr_eval], label='train')\n",
    "plt.plot([a[1] for a in te_eval], label='test')\n",
    "plt.xlabel('Accuracy')\n",
    "plt.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test['data']\n",
    "test_data = data_normalization(test_data)\n",
    "\n",
    "Y_pred = [model(w, test_data[i]) for i in range(test_data.shape[0])]\n",
    "\n",
    "# Saving data\n",
    "with open('solution.csv', 'w') as fout:\n",
    "    print(\"Id,Prediction\", file=fout)\n",
    "    for i in range(len(test_data)):\n",
    "        print(i, Y_pred[i], sep=',', file=fout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
